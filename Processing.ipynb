{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtGOPavgGlu5XBTEsZYQni"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **DATA PREP**\n","\n","Taking 300 collected images from JMARS and using aggressive augmentation to transform them x10-15 and resizing to a uniform size.\n","\n","\n","HUMAN"],"metadata":{"id":"-_k2GzcMIf7G"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"hpaTiqmEQQAb","executionInfo":{"status":"error","timestamp":1756905947932,"user_tz":-120,"elapsed":37822,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}},"outputId":"289d2a96-311c-4738-81b5-fba95022a906"},"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"markdown","source":["**RESIZE**\n","\n","To 128x128 pixels"],"metadata":{"id":"1uxA9iEvgtSE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4ZAw5bhIbWv","executionInfo":{"status":"aborted","timestamp":1756905948007,"user_tz":-120,"elapsed":79,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"outputs":[],"source":["import os\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Set up input and output paths\n","base_input_path = '/content/drive/MyDrive/Dissertation/DATA'\n","base_output_path = '/content/drive/MyDrive/Dissertation/Resized2'\n","classes = ['Impact', 'Volcanic']\n","\n","# Resize to 128x128 pixels\n","target_size = (128, 128)\n","\n","for cls in classes:\n","    input_dir = os.path.join(base_input_path, cls)\n","    output_dir = os.path.join(base_output_path, cls)\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for filename in tqdm(os.listdir(input_dir), desc=f\"Resizing {cls}\"):\n","        if not filename.lower().endswith('.png'):\n","            continue\n","        input_path = os.path.join(input_dir, filename)\n","        output_path = os.path.join(output_dir, filename)\n","\n","        img = Image.open(input_path).convert('RGB')  # Ensures 3-channel\n","        img_resized = img.resize(target_size, Image.BILINEAR)\n","        img_resized.save(output_path)\n"]},{"cell_type":"markdown","source":["**AUGMENTATION**\n","\n","300 images to 3000"],"metadata":{"id":"k6zTMMAwhGr2"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n","import random\n","from PIL import ImageFilter\n","\n","# Augmentation settings\n","datagen = ImageDataGenerator(\n","    rotation_range=360,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.2,\n","    brightness_range=[0.8, 1.2],\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# Optional: add slight noise\n","def add_noise(image_array, noise_level=10):\n","    noise = np.random.normal(0, noise_level, image_array.shape).astype(np.float32)\n","    noisy = image_array.astype(np.float32) + noise\n","    return np.clip(noisy, 0, 255).astype(np.uint8)\n","\n","# Optional: add blur\n","def apply_blur(pil_image, radius=1):\n","    return pil_image.filter(ImageFilter.GaussianBlur(radius))\n","\n","# Paths\n","resize_input_path = '/content/drive/MyDrive/Dissertation/Resized2'\n","augment_output_path = '/content/drive/MyDrive/Dissertation/Augmented2'\n","n_aug_per_image = 10\n","\n","for cls in classes:\n","    input_dir = os.path.join(resize_input_path, cls)\n","    output_dir = os.path.join(augment_output_path, cls)\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for file in tqdm(os.listdir(input_dir), desc=f\"Augmenting {cls}\"):\n","        if not file.lower().endswith('.png'):\n","            continue\n","\n","        img_path = os.path.join(input_dir, file)\n","        img = Image.open(img_path).convert('RGB')\n","        x = img_to_array(img).reshape((1,) + img.size + (3,))\n","\n","        i = 0\n","        for batch in datagen.flow(x, batch_size=1):\n","            aug = batch[0].astype('uint8')\n","            aug_img = Image.fromarray(aug)\n","\n","            # Optional: apply noise and blur\n","            if random.random() < 0.5:\n","                aug = add_noise(np.array(aug_img))\n","                aug_img = Image.fromarray(aug)\n","\n","            if random.random() < 0.5:\n","                aug_img = apply_blur(aug_img, radius=1)\n","\n","            aug_filename = f\"{file[:-4]}_aug_{i}.png\"\n","            aug_img.save(os.path.join(output_dir, aug_filename))\n","\n","            i += 1\n","            if i >= n_aug_per_image:\n","                break\n"],"metadata":{"id":"__zhTmkjYR8G","executionInfo":{"status":"aborted","timestamp":1756905948009,"user_tz":-120,"elapsed":79,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Sort Folders in google drive\n","\n","import os\n","import shutil\n","import random\n","\n","# Source directory\n","source_dir = '/content/drive/MyDrive/Dissertation/Augmented2'\n","\n","# Destination directory\n","base_output = '/content/drive/MyDrive/Dissertation/FinalDataset2'\n","\n","# Define subfolders\n","splits = ['train', 'val', 'test']\n","classes = ['Impact', 'Volcanic']\n","\n","# Create directory structure\n","for split in splits:\n","    for cls in classes:\n","        path = os.path.join(base_output, split, cls)\n","        os.makedirs(path, exist_ok=True)\n","\n","# Split ratios\n","train_ratio = 0.8\n","val_ratio = 0.1\n","test_ratio = 0.1\n","\n","for cls in classes:\n","    class_path = os.path.join(source_dir, cls)\n","    images = [f for f in os.listdir(class_path) if f.endswith('.png')]\n","    random.shuffle(images)\n","\n","    total = len(images)\n","    train_cut = int(train_ratio * total)\n","    val_cut = int(val_ratio * total)\n","\n","    split_data = {\n","        'train': images[:train_cut],\n","        'val': images[train_cut:train_cut + val_cut],\n","        'test': images[train_cut + val_cut:]\n","    }\n","\n","    for split in splits:\n","        for img in split_data[split]:\n","            src = os.path.join(class_path, img)\n","            dst = os.path.join(base_output, split, cls, img)\n","            shutil.copyfile(src, dst)\n"],"metadata":{"id":"lZwMllltmAhP","executionInfo":{"status":"aborted","timestamp":1756905948013,"user_tz":-120,"elapsed":83,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","base_dir = '/content/drive/MyDrive/Dissertation/FinalDataset2'\n","\n","for split in ['train', 'val', 'test']:\n","    print(f\"\\n{split.upper()}:\")\n","    for cls in ['Impact', 'Volcanic']:\n","        path = os.path.join(base_dir, split, cls)\n","        count = len([f for f in os.listdir(path) if f.endswith('.png') or f.endswith('.jpg')])\n","        print(f\"  {cls}: {count} images\")\n"],"metadata":{"id":"rlgyJMoXwvPm","executionInfo":{"status":"aborted","timestamp":1756905948037,"user_tz":-120,"elapsed":107,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find '/content/drive/MyDrive/Dissertation/DATA/Impact' -name '*.png' | wc -l\n","!find '/content/drive/MyDrive/Dissertation/DATA/Volcanic' -name '*.png' | wc -l\n","\n","!find '/content/drive/MyDrive/Dissertation/Resized/Impact' -name '*.png' | wc -l\n","!find '/content/drive/MyDrive/Dissertation/Resized/Volcanic' -name '*.png' | wc -l\n","\n","\n","!find '/content/drive/MyDrive/Dissertation/Augmented/Impact' -name '*.png' | wc -l\n","!find '/content/drive/MyDrive/Dissertation/Augmented/Volcanic' -name '*.png' | wc -l\n","\n","!find '/content/drive/MyDrive/Dissertation/FinalDataset/train/Volcanic' -name '*.png' | wc -l\n","!find '/content/drive/MyDrive/Dissertation/FinalDataset/train/Impact' -name '*.png' | wc -l\n","\n","\n","!find '/content/drive/MyDrive/Dissertation/FinalDataset/val/Volcanic' -name '*.png' | wc -l\n","!find '/content/drive/MyDrive/Dissertation/FinalDataset/val/Impact' -name '*.png' | wc -l\n","\n","\n","!find '/content/drive/MyDrive/Dissertation/FinalDataset/test/Volcanic' -name '*.png' | wc -l\n","!find '/content/drive/MyDrive/Dissertation/FinalDataset/test/Impact' -name '*.png' | wc -l\n","\n","\n"],"metadata":{"id":"UsF7vvUSw_Yt","executionInfo":{"status":"aborted","timestamp":1756905948038,"user_tz":-120,"elapsed":38043,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np, glob, os\n","\n","def avg_hash(img, hash_size=8):\n","    img = img.resize((hash_size, hash_size)).convert('L')\n","    arr = np.array(img)\n","    return tuple((arr > arr.mean()).flatten().astype(int))\n","\n","root = '/content/drive/MyDrive/Dissertation/FinalDataset2'  # or your dataset path\n","files = []\n","for split in ['train','val','test']:\n","    for cls in ['Impact','Volcanic']:\n","        path = os.path.join(root, split, cls)\n","        files += glob.glob(os.path.join(path, '*.*'))\n","\n","hash_map = {}\n","for f in files:\n","    try:\n","        h = avg_hash(Image.open(f))\n","        hash_map.setdefault(h, []).append(f)\n","    except Exception as e:\n","        pass\n","\n","collisions = [lst for lst in hash_map.values() if len(lst) > 1]\n","print(\"Groups of visually identical/near-duplicate images:\", len(collisions))\n","for grp in collisions[:10]:\n","    print(grp)\n"],"metadata":{"id":"RwQhPsYs8r6R","executionInfo":{"status":"aborted","timestamp":1756905948039,"user_tz":-120,"elapsed":38043,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, glob, re\n","from collections import defaultdict\n","\n","root = '/content/drive/MyDrive/Dissertation/FinalDataset2'  # replace with your actual FinalDataset path (FinalDataset, FinalDataset2, etc.)\n","\n","splits = ['train','val','test']\n","classes = ['Impact','Volcanic']\n","\n","# Map prefix -> set(splits) and sample files\n","prefix_splits = defaultdict(set)\n","prefix_examples = defaultdict(list)\n","\n","def get_prefix(fn):\n","    # adjust if your naming is different; this expects 'prefix_aug_X.ext' or 'prefix.ext'\n","    base = os.path.basename(fn)\n","    name = os.path.splitext(base)[0]\n","    if '_aug_' in name:\n","        return name.split('_aug_')[0]\n","    # if you used other separators, add here\n","    return name\n","\n","for split in splits:\n","    for cls in classes:\n","        folder = os.path.join(root, split, cls)\n","        if not os.path.exists(folder):\n","            continue\n","        for f in glob.glob(os.path.join(folder, '*.*')):\n","            p = get_prefix(f)\n","            prefix_splits[p].add(split)\n","            if len(prefix_examples[p]) < 5:\n","                prefix_examples[p].append((split, f))\n","\n","# find prefixes that appear in multiple splits\n","multi_split_prefixes = [p for p, sset in prefix_splits.items() if len(sset) > 1]\n","print(\"Total unique original prefixes found:\", len(prefix_splits))\n","print(\"Prefixes appearing in more than one split:\", len(multi_split_prefixes))\n","if len(multi_split_prefixes) > 0:\n","    print(\"Examples (prefix -> splits -> sample files):\")\n","    for p in multi_split_prefixes[:20]:\n","        print(p, \"->\", prefix_splits[p])\n","        for ex in prefix_examples[p]:\n","            print(\"   \", ex)\n","else:\n","    print(\"No original-prefix appears in multiple splits. Good â€” no grouped-sibling leakage detected.\")\n"],"metadata":{"id":"2u3pazkC8-u8","executionInfo":{"status":"aborted","timestamp":1756905948040,"user_tz":-120,"elapsed":38044,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","for split in ['train','val','test']:\n","    counts = Counter()\n","    for cls in ['Impact','Volcanic']:\n","        folder = os.path.join(root, split, cls)\n","        counts[cls] = len(glob.glob(os.path.join(folder, '*.*')))\n","    print(split, counts)\n"],"metadata":{"id":"bkIY68Bc9Hkg","executionInfo":{"status":"aborted","timestamp":1756905948044,"user_tz":-120,"elapsed":38047,"user":{"displayName":"Madeleine Carnell","userId":"06721214310523517188"}}},"execution_count":null,"outputs":[]}]}